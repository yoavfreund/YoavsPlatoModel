
\noindent \textbf{Probabilistic models.} For ease of exposition, models have been defined above as returning absolute values. However, since they are inherently statistical approximations of the underlying process (based on the underlying measurements), models should have a probabilistic component. Adding probabilistic information to a model can be done in many ways. We next outline three alternatives, explain their connection to prior works in probabilistic databases and signal processing, and argue for the one we adopt in \projName. In the subsequent definitions we assume that the domain of the model is $\mathcal{D} \subseteq \mathcal{D}_{xyzt}$ and its intended range (leaving aside the probabilities) is $\mathcal{Q}$. 

\noindent \emph{Model as a probability distribution over functions.} A \emph{function-probability} model is a probability distribution over all functions $f:\mathcal{D} \mapsto \mathcal{Q}$. Drawing an analogy with probabilistic databases, a function-probability model corresponds to a probabilistic database defined as a probability distribution over the set of database instances that constitute the set of possible worlds. Although such a definition of probabilistic databases is the most general and thus guaranteed to cover any use cases, we are not aware of any practical system using this definition of probabilistic database. Similarly, function-probability models, are merely of theoretical interest.

\noindent \emph{Model as a probability distribution over values.} A \emph{value-probability} model is a function from $\mathcal{D}$ to probability distributions of $Q$. Continuing our analogy, this definition corresponds to probabilistic databases where each tuple has a set of possible instantiations with associated probabilities that are independent of the other tuples. It is easy to see that value-probability models are strictly less expressive than function-probability models, since each point in $\mathcal{D}$ is assigned a probability distribution of possible values independently of the other points. While this definition is more practical than function-probability models, it is still too general for practical use. To this end, we introduce a third definition of probabilistic models, which leverages the tried-and-true work of the signal processing community in modeling signals.

\noindent \emph{Model as a combination of signal and noise.} A \emph{signal-noise} model is a function $f(i) = s(i) + \alpha(i) n(i)$, $\forall i \in D$, where $s: \mathcal{D} \mapsto \mathcal{Q}$ is a non-probabilistic function representing the signal, $n$ is a noise function from $\mathcal{D}$ to probability distributions over $Q$ representing the noise and $\alpha: \mathcal{D} \mapsto N$ is a function representing the amplitude of the noise. According to this definition, the signal is a deterministic function; the probabilistic aspect comes simply from the noise that is added to the signal. A  commonly-used noise function is the {\em white noise}, which is the well known gaussian distribution $N(0,1)$.\cite{statistical-signal-processing-textbook}.
\reminder{Do we want to have a special case of the above definition, where we use the same probability distribution for all points in $\mathcal{D}$?} \reminder{In theory yes. But I wrote that we leverage ``signal processing work" and i do not know of such work. I was more comfortable adding the white noise specialization.
}

\projName\ employs the signal-noise probabilistic model definition as its value in capturing real use cases has been successfully proven by the signal processing community. Moreover, this approach allows models to separate the signal from the noise, leading to high quality data, as we will be discussing in Section \ref{sec:compression}.

%models return in reality probability distributions of the quantities, rather than absolute values. Therefore a model is a function $f:\mathcal{D}\mapsto \mathcal{H_{Q}}$, where $\mathcal{H_{Q}}$ is the space of probability distributions over the quantity domain $\mathcal{Q}$. The probability distributions capture the certainty of the predicted values. For example, the model of Example~\ref{xmpl:models-and-definitions} can easily benefit from returning probability distributions of the predicted temperatures. A common way of displaying the probability distribution of a quantity to the end user is through a triple $(p, v, \epsilon)$, denoting that the the quantity's value falls within the interval $[v - \epsilon, v + \epsilon]$ with probability $p$.\\

%\paragraph{Viewing models as infinitely-sized tables} Notice that a model $f:\mathcal{\bar{D}}\mapsto \mathcal{H_{\bar{Q}}}$ can be also perceived as a table $R_f(\bar{D}, \bar{Q}, H)$, where the table has an infinite number of tuples, the coordinates $\bar{D}$ form a key and the attribute $H$ provides the value of the probability distribution at the specific coordinates.
%Correspondingly, the models that are the values of a table's attribute can be perceived as infinite size nested tables.%

